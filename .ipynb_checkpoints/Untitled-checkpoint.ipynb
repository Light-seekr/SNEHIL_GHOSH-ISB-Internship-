{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34191584-e69d-4147-ad38-e176941b4acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_mic_gesture_streamlit.py\n",
    "# Merged: MC_debug04 mic logic (untouched) + Debug02 MediaPipe gesture Streamlit UI\n",
    "# Run on Windows. Requires: pip install pycaw comtypes mediapipe opencv-python streamlit plotly\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import threading\n",
    "import platform\n",
    "import queue\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "from collections import deque\n",
    "\n",
    "# --- MC_debug04 COM / mic logic (kept intact) ---\n",
    "from ctypes import POINTER, cast\n",
    "from comtypes import CLSCTX_ALL, CoInitialize, CoUninitialize\n",
    "from comtypes.client import CreateObject\n",
    "from comtypes import GUID\n",
    "\n",
    "# keyboard is not required for Streamlit main loop; mic logic preserved.\n",
    "try:\n",
    "    import keyboard  # optional; MC logic referenced it. If not needed, ignore errors when not used.\n",
    "except Exception:\n",
    "    # keyboard is optional for this merged app; hotkeys usage is preserved in function form only.\n",
    "    keyboard = None\n",
    "\n",
    "try:\n",
    "    from pycaw.pycaw import IAudioEndpointVolume, IMMDeviceEnumerator\n",
    "except Exception:\n",
    "    raise SystemExit(\"Install required packages: pip install pycaw comtypes\")\n",
    "\n",
    "# Constants from MC_debug04\n",
    "eCapture = 1\n",
    "eConsole = 0\n",
    "STEP_PERCENT = 2\n",
    "\n",
    "# --- Cooldown settings from MC_debug04 (preserved) ---\n",
    "LAST_TRIGGER = {\"inc\": 0, \"dec\": 0}\n",
    "COOLDOWN_SECONDS = 0.15\n",
    "\n",
    "\n",
    "def allow_action(action_key):\n",
    "    \"\"\"Return True if cooldown time has passed for this action.\"\"\"\n",
    "    import time as _t\n",
    "    now = _t.time()\n",
    "    if now - LAST_TRIGGER[action_key] >= COOLDOWN_SECONDS:\n",
    "        LAST_TRIGGER[action_key] = now\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def _create_mmdevice_enumerator():\n",
    "    try:\n",
    "        return CreateObject(\"MMDeviceEnumerator.MMDeviceEnumerator\", interface=IMMDeviceEnumerator)\n",
    "    except Exception:\n",
    "        clsid = GUID(\"{BCDE0395-E52F-467C-8E3D-C4579291692E}\")\n",
    "        return CreateObject(clsid, interface=IMMDeviceEnumerator)\n",
    "\n",
    "\n",
    "def _get_volume_interface_for_default():\n",
    "    enumerator = _create_mmdevice_enumerator()\n",
    "    default_device = enumerator.GetDefaultAudioEndpoint(eCapture, eConsole)\n",
    "    iface = default_device.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "    return cast(iface, POINTER(IAudioEndpointVolume))\n",
    "\n",
    "\n",
    "def _percent_to_scalar(p):\n",
    "    return max(0.0, min(1.0, p / 100.0))\n",
    "\n",
    "\n",
    "def _scalar_to_percent(s):\n",
    "    return max(0.0, min(100.0, s * 100.0))\n",
    "\n",
    "\n",
    "def ensure_com(func):\n",
    "    \"\"\"Decorator from MC_debug04: CoInitialize() before call, CoUninitialize() after.\"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        CoInitialize()\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            print(\"Exception in handler:\", file=sys.stderr)\n",
    "            traceback.print_exc()\n",
    "        finally:\n",
    "            try:\n",
    "                CoUninitialize()\n",
    "            except Exception:\n",
    "                pass\n",
    "    wrapper.__name__ = func.__name__\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "# The original functions from MC_debug04 (kept as-is)\n",
    "@ensure_com\n",
    "def increase_volume():\n",
    "    if not allow_action(\"inc\"):\n",
    "        return\n",
    "    vol = _get_volume_interface_for_default()\n",
    "    cur = float(vol.GetMasterVolumeLevelScalar())\n",
    "    cur_pct = _scalar_to_percent(cur)\n",
    "    new_pct = min(100.0, cur_pct + STEP_PERCENT)\n",
    "    vol.SetMasterVolumeLevelScalar(_percent_to_scalar(new_pct), None)\n",
    "    print(f\"[+] Mic volume -> {new_pct:.0f}%\")\n",
    "\n",
    "\n",
    "@ensure_com\n",
    "def decrease_volume():\n",
    "    if not allow_action(\"dec\"):\n",
    "        return\n",
    "    vol = _get_volume_interface_for_default()\n",
    "    cur = float(vol.GetMasterVolumeLevelScalar())\n",
    "    cur_pct = _scalar_to_percent(cur)\n",
    "    new_pct = max(0.0, cur_pct - STEP_PERCENT)\n",
    "    vol.SetMasterVolumeLevelScalar(_percent_to_scalar(new_pct), None)\n",
    "    print(f\"[-] Mic volume -> {new_pct:.0f}%\")\n",
    "\n",
    "\n",
    "@ensure_com\n",
    "def toggle_mute():\n",
    "    vol = _get_volume_interface_for_default()\n",
    "    cur_mute = bool(vol.GetMute())\n",
    "    vol.SetMute(0 if cur_mute else 1, None)\n",
    "    print(f\"[{'M' if not cur_mute else 'U'}] Mic muted -> {not cur_mute}\")\n",
    "\n",
    "\n",
    "@ensure_com\n",
    "def get_mic_state():\n",
    "    \"\"\"Return (level_percent, muted) same approach as MC_debug04's get_mic_state.\"\"\"\n",
    "    try:\n",
    "        vol = _get_volume_interface_for_default()\n",
    "        level = int(_scalar_to_percent(float(vol.GetMasterVolumeLevelScalar())))\n",
    "        mute = bool(vol.GetMute())\n",
    "        return level, mute\n",
    "    except Exception:\n",
    "        return 50, False\n",
    "\n",
    "\n",
    "# Minimal wrappers used by Streamlit gesture code to read/set mic volume\n",
    "@ensure_com\n",
    "def set_mic_volume_percent(vol_percent: int):\n",
    "    \"\"\"Set microphone (capture endpoint) master level as integer 0-100.\"\"\"\n",
    "    try:\n",
    "        vol = _get_volume_interface_for_default()\n",
    "        vol_percent = int(max(0, min(100, vol_percent)))\n",
    "        vol.SetMasterVolumeLevelScalar(_percent_to_scalar(vol_percent), None)\n",
    "    except Exception as e:\n",
    "        # fail-safe: print for debugging; don't crash streamlit loop\n",
    "        print(\"set_mic_volume_percent error:\", e)\n",
    "\n",
    "\n",
    "@ensure_com\n",
    "def get_mic_volume_percent() -> int:\n",
    "    \"\"\"Return current mic master level as integer 0-100. On error, return 50.\"\"\"\n",
    "    try:\n",
    "        vol = _get_volume_interface_for_default()\n",
    "        return int(_scalar_to_percent(float(vol.GetMasterVolumeLevelScalar())))\n",
    "    except Exception as e:\n",
    "        print(\"get_mic_volume_percent error:\", e)\n",
    "        return 50\n",
    "\n",
    "\n",
    "# --- End of MC_debug04 logic ---\n",
    "\n",
    "\n",
    "# ---------------- Streamlit app (Debug02) with MediaPipe (hand gestures) ----------------\n",
    "# Keep gesture logic and UI intact, but call the mic functions above to control microphone volume.\n",
    "\n",
    "# Safety: require Windows\n",
    "if platform.system() != \"Windows\":\n",
    "    raise SystemExit(\"This merged script runs only on Windows (pycaw microphone control).\")\n",
    "\n",
    "# Streamlit page config\n",
    "st.set_page_config(page_title=\"Mic Volume Control using MediaPipe ‚Äî Streamlit\", layout=\"wide\")\n",
    "\n",
    "# ---------------- Configuration (kept from Debug02) ----------------\n",
    "CAM_INDEX = 0\n",
    "PINCH_PIXEL_THRESHOLD = 40\n",
    "PINCH_NORM_THRESHOLD = 0.03\n",
    "MIN_DIST = 25\n",
    "MAX_DIST = 190\n",
    "VOLUME_STEP_THRESHOLD = 4\n",
    "MAX_BUFFER_LEN = 150\n",
    "\n",
    "# ---------------- Mediapipe (kept) ----------------\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "if \"hands\" not in st.session_state:\n",
    "    st.session_state[\"hands\"] = mp_hands.Hands(\n",
    "        static_image_mode=False,\n",
    "        model_complexity=1,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5,\n",
    "        max_num_hands=2\n",
    "    )\n",
    "hands = st.session_state[\"hands\"]\n",
    "\n",
    "# Replace old speaker-based Pycaw init: we use MC_debug04 functions instead.\n",
    "# Provide the Streamlit-callable helpers expected by original code:\n",
    "def set_system_volume(vol_percent):\n",
    "    \"\"\"Streamlit logic calls this ‚Äî route to microphone setter (kept behavior of setting scalar).\"\"\"\n",
    "    set_mic_volume_percent(int(vol_percent))\n",
    "\n",
    "\n",
    "def get_system_volume():\n",
    "    \"\"\"Return current mic volume percent for seeding prev_volume in state.\"\"\"\n",
    "    return get_mic_volume_percent()\n",
    "\n",
    "\n",
    "# ---------------- Frame Processing (kept from Debug02, unchanged except volume setter call routed above) ----------------\n",
    "def process_frame(frame, prev_pixel_dist, prev_volume):\n",
    "    img_h, img_w = frame.shape[:2]\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(frame_rgb)\n",
    "\n",
    "    norm_dist = None\n",
    "    pixel_dist = None\n",
    "    pinch = False\n",
    "    handedness_label = None\n",
    "    current_volume = prev_volume\n",
    "    aspect_ratio = None\n",
    "\n",
    "    if results.multi_hand_landmarks and len(results.multi_hand_landmarks) > 0:\n",
    "        hand_landmarks = results.multi_hand_landmarks[0]\n",
    "        lm_thumb = hand_landmarks.landmark[4]\n",
    "        lm_index = hand_landmarks.landmark[8]\n",
    "\n",
    "        dx_n = lm_thumb.x - lm_index.x\n",
    "        dy_n = lm_thumb.y - lm_index.y\n",
    "        dz_n = lm_thumb.z - lm_index.z\n",
    "        norm_dist = math.sqrt(dx_n ** 2 + dy_n ** 2 + dz_n ** 2)\n",
    "\n",
    "        tx_px = int(round(lm_thumb.x * img_w))\n",
    "        ty_px = int(round(lm_thumb.y * img_h))\n",
    "        ix_px = int(round(lm_index.x * img_w))\n",
    "        iy_px = int(round(lm_index.y * img_h))\n",
    "        pixel_dist = math.hypot(tx_px - ix_px, ty_px - iy_px)\n",
    "\n",
    "        if pixel_dist <= PINCH_PIXEL_THRESHOLD or (norm_dist is not None and norm_dist <= PINCH_NORM_THRESHOLD):\n",
    "            pinch = True\n",
    "\n",
    "        xs = [lm.x for lm in hand_landmarks.landmark]\n",
    "        ys = [lm.y for lm in hand_landmarks.landmark]\n",
    "        width = max(xs) - min(xs)\n",
    "        height = max(ys) - min(ys)\n",
    "        if height > 0:\n",
    "            aspect_ratio = width / height\n",
    "\n",
    "        mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "        cv2.circle(frame, (tx_px, ty_px), 10, (0, 0, 255), -1)\n",
    "        cv2.circle(frame, (ix_px, iy_px), 10, (255, 0, 0), -1)\n",
    "        cv2.line(frame, (tx_px, ty_px), (ix_px, iy_px), (0, 255, 0), 3)\n",
    "\n",
    "        mid_x = (tx_px + ix_px) // 2\n",
    "        mid_y = (ty_px + iy_px) // 2\n",
    "        cv2.circle(frame, (mid_x, mid_y), 10, (0, 255, 255), -1)\n",
    "\n",
    "        if pixel_dist is not None:\n",
    "            new_volume = np.interp(pixel_dist, [MIN_DIST, MAX_DIST], [0, 100])\n",
    "            new_volume = int(np.clip(new_volume, 0, 100))\n",
    "            if abs(new_volume - prev_volume) >= VOLUME_STEP_THRESHOLD:\n",
    "                # This is now routed to MC_debug04 mic setter (logic intact).\n",
    "                set_system_volume(new_volume)\n",
    "                current_volume = new_volume\n",
    "\n",
    "        cv2.putText(frame, f\"Volume: {current_volume}%\", (mid_x - 80, mid_y - 60),\n",
    "                    cv2.FONT_HERSHEY_DUPLEX, 1.0, (255, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        if results.multi_handedness:\n",
    "            try:\n",
    "                handedness_label = results.multi_handedness[0].classification[0].label\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    base_y = 30\n",
    "    dy_text = 30\n",
    "    lines = []\n",
    "    if handedness_label:\n",
    "        lines.append(f\"Hand: {handedness_label}\")\n",
    "    if norm_dist is not None:\n",
    "        lines.append(f\"Norm: {norm_dist:.4f}\")\n",
    "    if pixel_dist is not None:\n",
    "        lines.append(f\"Pixel: {pixel_dist:.1f}px\")\n",
    "    lines.append(f\"Pinch: {'YES' if pinch else 'NO'}\")\n",
    "\n",
    "    for i, txt in enumerate(lines):\n",
    "        cv2.putText(frame, txt, (10, base_y + i * dy_text),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    return frame, norm_dist, pixel_dist, pinch, current_volume, aspect_ratio\n",
    "\n",
    "\n",
    "# ---------------- Streamlit UI (kept from Debug02) ----------------\n",
    "st.title(\"üéõÔ∏è Mic Volume Control using MediaPipe ‚Äî Streamlit Edition\")\n",
    "st.markdown(\"**Controls:** Start/Stop Camera ‚Äî Real-time graphs + Pycaw microphone control.\")\n",
    "\n",
    "col1, col2 = st.columns([2, 1])\n",
    "\n",
    "with col2:\n",
    "    if \"running\" not in st.session_state:\n",
    "        st.session_state[\"running\"] = False\n",
    "    if \"cap\" not in st.session_state:\n",
    "        st.session_state[\"cap\"] = None\n",
    "    if \"prev_pixel_dist\" not in st.session_state:\n",
    "        st.session_state[\"prev_pixel_dist\"] = None\n",
    "    if \"prev_volume\" not in st.session_state:\n",
    "        # seed prev_volume from microphone state (MC logic)\n",
    "        st.session_state[\"prev_volume\"] = get_system_volume()\n",
    "    if \"timestamps\" not in st.session_state:\n",
    "        st.session_state[\"timestamps\"] = deque(maxlen=MAX_BUFFER_LEN)\n",
    "    if \"norm_dists\" not in st.session_state:\n",
    "        st.session_state[\"norm_dists\"] = deque(maxlen=MAX_BUFFER_LEN)\n",
    "    if \"pixel_dists\" not in st.session_state:\n",
    "        st.session_state[\"pixel_dists\"] = deque(maxlen=MAX_BUFFER_LEN)\n",
    "    if \"aspect_ratios\" not in st.session_state:\n",
    "        st.session_state[\"aspect_ratios\"] = deque(maxlen=MAX_BUFFER_LEN)\n",
    "\n",
    "    start_btn = st.button(\"‚ñ∂Ô∏è Start Camera\")\n",
    "    stop_btn = st.button(\"‚èπ Stop Camera\")\n",
    "\n",
    "# Placeholders\n",
    "img_placeholder = col1.empty()\n",
    "status_placeholder = col1.empty()\n",
    "plot1_placeholder = st.empty()\n",
    "plot2_placeholder = st.empty()\n",
    "\n",
    "# Start camera\n",
    "if start_btn:\n",
    "    if not st.session_state[\"running\"]:\n",
    "        cap = cv2.VideoCapture(CAM_INDEX, cv2.CAP_DSHOW)\n",
    "        st.session_state[\"cap\"] = cap\n",
    "        if not st.session_state[\"cap\"].isOpened():\n",
    "            st.error(\"‚ùå Cannot open camera. Check permissions.\")\n",
    "        else:\n",
    "            st.session_state[\"running\"] = True\n",
    "            st.session_state[\"timestamps\"].clear()\n",
    "            st.session_state[\"norm_dists\"].clear()\n",
    "            st.session_state[\"pixel_dists\"].clear()\n",
    "            st.session_state[\"aspect_ratios\"].clear()\n",
    "            st.session_state[\"start_time\"] = time.time()\n",
    "            st.success(\"‚úÖ Camera started.\")\n",
    "\n",
    "# Stop camera\n",
    "if stop_btn:\n",
    "    if st.session_state[\"running\"]:\n",
    "        st.session_state[\"running\"] = False\n",
    "        if st.session_state[\"cap\"] and st.session_state[\"cap\"].isOpened():\n",
    "            st.session_state[\"cap\"].release()\n",
    "        try:\n",
    "            hands.close()\n",
    "        except:\n",
    "            pass\n",
    "        st.success(\"üõë Camera stopped.\")\n",
    "\n",
    "# Main loop (kept, with mic-set calls routed to MC logic)\n",
    "if st.session_state[\"running\"] and st.session_state[\"cap\"] is not None:\n",
    "    cap = st.session_state[\"cap\"]\n",
    "    frame_count = 0\n",
    "    while st.session_state[\"running\"] and frame_count < 8:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            st.warning(\"‚ö†Ô∏è Frame read failed. Stopping.\")\n",
    "            st.session_state[\"running\"] = False\n",
    "            cap.release()\n",
    "            break\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        frame, norm_dist, pixel_dist, pinch, st.session_state[\"prev_volume\"], aspect_ratio = process_frame(\n",
    "            frame, st.session_state[\"prev_pixel_dist\"], st.session_state[\"prev_volume\"]\n",
    "        )\n",
    "        st.session_state[\"prev_pixel_dist\"] = pixel_dist\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img_placeholder.image(frame_rgb, channels=\"RGB\", use_column_width=True)\n",
    "\n",
    "        elapsed = time.time() - st.session_state[\"start_time\"]\n",
    "        st.session_state[\"timestamps\"].append(elapsed)\n",
    "        st.session_state[\"norm_dists\"].append(norm_dist if norm_dist else np.nan)\n",
    "        st.session_state[\"pixel_dists\"].append(pixel_dist if pixel_dist else np.nan)\n",
    "        st.session_state[\"aspect_ratios\"].append(aspect_ratio if aspect_ratio else np.nan)\n",
    "\n",
    "        t_arr = np.array(st.session_state[\"timestamps\"])\n",
    "        norm_arr = np.array(st.session_state[\"norm_dists\"])\n",
    "        pix_arr = np.array(st.session_state[\"pixel_dists\"])\n",
    "        aspect_arr = np.array(st.session_state[\"aspect_ratios\"])\n",
    "\n",
    "        # Plot 1 (unchanged)\n",
    "        factor = 1\n",
    "        if np.nanmax(norm_arr) > 0 and np.nanmax(pix_arr) > 0:\n",
    "            factor = (np.nanmax(norm_arr) + 1e-6) / (np.nanmax(pix_arr) + 1e-6)\n",
    "        scaled_pix = pix_arr * factor\n",
    "\n",
    "        fig1 = None\n",
    "        try:\n",
    "            import plotly.graph_objects as go\n",
    "            fig1 = go.Figure()\n",
    "            fig1.add_trace(go.Scatter(x=t_arr, y=norm_arr, mode=\"lines+markers\", name=\"Norm\"))\n",
    "            fig1.add_trace(go.Scatter(x=t_arr, y=scaled_pix, mode=\"lines+markers\", name=\"Pixel (scaled)\"))\n",
    "            fig1.update_layout(title=\"üìà Live Norm & Pixel\", height=300)\n",
    "            plot1_placeholder.plotly_chart(fig1, use_container_width=True)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # Plot 2\n",
    "        fig2 = None\n",
    "        try:\n",
    "            fig2 = go.Figure()\n",
    "            fig2.add_trace(go.Scatter(x=t_arr, y=aspect_arr, mode=\"lines+markers\", name=\"Aspect Ratio\"))\n",
    "            fig2.update_layout(title=\"üìä Aspect Ratio\", height=300)\n",
    "            plot2_placeholder.plotly_chart(fig2, use_container_width=True)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # ‚úÖ Safe formatting for None values\n",
    "        norm_str = f\"{norm_dist:.4f}\" if norm_dist is not None else \"0.0000\"\n",
    "        pix_str = f\"{pixel_dist:.1f}\" if pixel_dist is not None else \"0.0\"\n",
    "        asp_str = f\"{aspect_ratio:.2f}\" if aspect_ratio is not None else \"N/A\"\n",
    "\n",
    "        now = time.strftime(\"%H:%M:%S\")\n",
    "        status_placeholder.markdown(\n",
    "            f\"**[{now}] | Norm={norm_str} | Pixel={pix_str}px | Aspect={asp_str} | Volume={st.session_state['prev_volume']}%**\"\n",
    "        )\n",
    "\n",
    "        frame_count += 1\n",
    "        time.sleep(0.03)\n",
    "\n",
    "    # Compatible rerun (kept)\n",
    "    if st.session_state[\"running\"]:\n",
    "        if hasattr(st, \"rerun\"):\n",
    "            st.rerun()\n",
    "        else:\n",
    "            st.experimental_rerun()\n",
    "else:\n",
    "    img_placeholder.image(np.zeros((480, 640, 3), dtype=np.uint8) + 20, channels=\"RGB\",\n",
    "                          caption=\"Camera not started\", use_column_width=True)\n",
    "    status_placeholder.info(\"Camera is stopped. Click ‚ñ∂Ô∏è Start Camera to begin.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
